# 📘 ON_LM_NewtonClosestUV: Surface Point Inversion

## 문제 정의
주어진 3D 점 **Q** 와 매개변수화된 곡면

$$
S(u,v): \mathbb{R}^2 \to \mathbb{R}^3
$$

가 있을 때, 목표는 **곡면 위의 최근접점**을 찾는 것이다:

$$
(u^*,v^*) = \arg\min_{(u,v)} f(u,v), \quad
$$

$$
f(u,v) = \tfrac{1}{2}\| S(u,v) - Q \|^2
$$



---

## 그래디언트와 헤세 행렬

### 잔차 벡터
$$
r(u,v) = S(u,v) - Q
$$

### 1계 미분 (Gradient)
$$
\frac{\partial f}{\partial u} = \langle r, S_u \rangle, \quad 
\frac{\partial f}{\partial v} = \langle r, S_v \rangle
$$

따라서

$$
\nabla f(u,v) =
\begin{bmatrix}
\langle r, S_u \rangle \\
\langle r, S_v \rangle
\end{bmatrix}
$$

### 2계 미분 (Hessian)
$$
\frac{\partial^2 f}{\partial u^2} = \langle S_u, S_u \rangle + \langle r, S_{uu} \rangle
$$
$$
\frac{\partial^2 f}{\partial u \partial v} = \langle S_u, S_v \rangle + \langle r, S_{uv} \rangle
$$
$$
\frac{\partial^2 f}{\partial v^2} = \langle S_v, S_v \rangle + \langle r, S_{vv} \rangle
$$

헤세 행렬:

$$
H =
\begin{bmatrix}
\langle S_u, S_u \rangle + \langle r, S_{uu} \rangle & \langle S_u, S_v \rangle + \langle r, S_{uv} \rangle \\
\langle S_u, S_v \rangle + \langle r, S_{uv} \rangle & \langle S_v, S_v \rangle + \langle r, S_{vv} \rangle
\end{bmatrix}
$$

---

## 뉴턴 업데이트

뉴턴법은

$$
\Delta =
\begin{bmatrix}
\Delta u \\ \Delta v
\end{bmatrix}
= - H^{-1} \nabla f
$$

업데이트:

$$
u \leftarrow u + \Delta u, \quad v \leftarrow v + \Delta v
$$

---

## Levenberg–Marquardt 감쇠

헤세가 특이하거나 수치적으로 불안정하면 발산할 수 있다.  
따라서 LM 감쇠 항을 추가:

$$
H' = H + \lambda I
$$

여기서 \(\lambda > 0\) 는 작은 값으로, 작은 고유값을 밀어올려 안정성을 높인다.

---

## 라인서치 (Backtracking)

스텝 크기를 직접 적용하면 overshoot 가능성이 있다.  
따라서 backtracking 으로 \(\alpha \in (0,1]\) 를 줄여가며 다음 조건 만족 시 채택한다:

$$
f(u - \alpha \Delta u, v - \alpha \Delta v) \le f(u,v) - c \alpha \| \nabla f \|^2
$$

실제 구현에서는 단순히 step을 ½씩 줄이며 잔차 감소 여부를 확인한다.

---

## 알고리즘 요약 (의사코드)

```cpp
(u,v) = 초기 시드 (coarse sampling or analytic)
for iter in 0..max_iter:
    S, Su, Sv, Suu, Suv, Svv = Evaluate(surface, u, v)
    r = S - Q

    // gradient
    g = [ dot(r, Su), dot(r, Sv) ]

    // Hessian with LM damping
    H = [[ dot(Su,Su)+dot(r,Suu), dot(Su,Sv)+dot(r,Suv) ],
         [ dot(Su,Sv)+dot(r,Suv), dot(Sv,Sv)+dot(r,Svv) ]]
    H += λ * I

    Δ = - H^{-1} g

    // line-search
    step = 1.0
    while step > min_step:
        u_new = normalize(u + step*Δu)
        v_new = normalize(v + step*Δv)
        if f(u_new,v_new) < f(u,v):
            accept; break
        step *= 0.5

    if |Δ|^2 < tol^2 or ||r||^2 < tol3d^2:
        return (u,v) 성공
